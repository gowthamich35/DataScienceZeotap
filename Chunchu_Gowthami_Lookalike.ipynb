{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw0SqVXKjDd2ZO5sPi6XpN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowthamich35/DataScienceZeotap/blob/main/Chunchu_Gowthami_Lookalike.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXKiG871uDRK",
        "outputId": "8552e845-b58d-4b8a-ce04-fc19f3da4756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lookalike.csv has been created.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler  # Ensure this is imported\n",
        "\n",
        "# Load the data\n",
        "cs = pd.read_csv('Customers.csv')\n",
        "ps = pd.read_csv('Products.csv')\n",
        "ts = pd.read_csv('Transactions.csv')\n",
        "\n",
        "# Step 1: Merge data\n",
        "# Merge transactions with customer data\n",
        "merged_data = pd.merge(ts, cs, on='CustomerID', how='inner')\n",
        "\n",
        "# Step 2: Feature Engineering\n",
        "# Create features like transaction frequency, total spent, most frequent product categories, etc.\n",
        "customer_profile = merged_data.groupby('CustomerID').agg(\n",
        "    total_spent=('TotalValue', 'sum'),\n",
        "    transaction_count=('TransactionID', 'count'),\n",
        "    most_frequent_category=('ProductID', lambda x: x.mode()[0])\n",
        ").reset_index()\n",
        "\n",
        "# Step 3: Merge product categories with the transactions data\n",
        "# Ensure that 'Category' column exists in the products data (ps)\n",
        "product_categories = ps[['ProductID', 'Category']]\n",
        "\n",
        "# Merge the product categories with the merged_data (transactions)\n",
        "merged_data = pd.merge(merged_data, product_categories, on='ProductID', how='left')\n",
        "\n",
        "# Calculate customer engagement with different categories\n",
        "category_engagement = merged_data.groupby(['CustomerID', 'Category']).size().unstack().fillna(0)\n",
        "\n",
        "# Combine all features into a single customer profile\n",
        "customer_profile = pd.merge(customer_profile, category_engagement, on='CustomerID', how='left')\n",
        "\n",
        "# Step 4: Prepare data for scaling (only numerical columns)\n",
        "# Drop non-numeric columns (e.g., 'CustomerID' and 'most_frequent_category')\n",
        "numerical_data = customer_profile.drop(['CustomerID', 'most_frequent_category'], axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "normalized_features = scaler.fit_transform(numerical_data)\n",
        "\n",
        "# Step 5: Calculate Similarity Scores\n",
        "# Calculate cosine similarity between customers\n",
        "cos_sim = cosine_similarity(normalized_features)\n",
        "\n",
        "# Step 6: Generate Recommendations for the first 20 customers\n",
        "lookalike_dict = {}\n",
        "\n",
        "for i in range(20):  # For CustomerID C0001 to C0020\n",
        "    # Get similarity scores for customer i\n",
        "    similarity_scores = cos_sim[i]\n",
        "    # Exclude the customer from their own lookalikes\n",
        "    similarity_scores[i] = -1\n",
        "    # Get the indices of the top 3 most similar customers\n",
        "    top_3_indices = similarity_scores.argsort()[-3:][::-1]\n",
        "\n",
        "    # Create a list of the top 3 lookalike customers and their similarity scores\n",
        "    top_3_lookalikes = [(cs.iloc[idx]['CustomerID'], similarity_scores[idx]) for idx in top_3_indices]\n",
        "    lookalike_dict[cs.iloc[i]['CustomerID']] = top_3_lookalikes\n",
        "\n",
        "# Step 7: Prepare the DataFrame correctly with the appropriate columns\n",
        "lookalike_data = []\n",
        "\n",
        "for customer_id, lookalikes in lookalike_dict.items():\n",
        "    for lookalike in lookalikes:\n",
        "        lookalike_data.append([customer_id, lookalike[0], lookalike[1]])\n",
        "\n",
        "# Create the DataFrame\n",
        "lookalike_df = pd.DataFrame(lookalike_data, columns=['CustomerID', 'Lookalike CustomerID', 'Similarity Score'])\n",
        "\n",
        "# Step 8: Output to CSV\n",
        "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
        "\n",
        "print(\"Lookalike.csv has been created.\")\n"
      ]
    }
  ]
}